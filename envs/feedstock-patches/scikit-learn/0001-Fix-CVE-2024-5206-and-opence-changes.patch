From 3dddc7b2af71e1a5b71ea54c8d21657e229893a0 Mon Sep 17 00:00:00 2001
From: Archana-Shinde1 <archana.shinde1@ibm.com>
Date: Tue, 8 Apr 2025 14:15:26 +0000
Subject: [PATCH] Fix CVE-2024-5206 and opence changes

---
 recipe/0001-Fix-of-CVE-2024-5206.patch | 204 +++++++++++++++++++++++++
 recipe/meta.yaml                       |  19 +--
 2 files changed, 209 insertions(+), 14 deletions(-)
 create mode 100644 recipe/0001-Fix-of-CVE-2024-5206.patch

diff --git a/recipe/0001-Fix-of-CVE-2024-5206.patch b/recipe/0001-Fix-of-CVE-2024-5206.patch
new file mode 100644
index 0000000..1793d3b
--- /dev/null
+++ b/recipe/0001-Fix-of-CVE-2024-5206.patch
@@ -0,0 +1,204 @@
+From e4eec8712d6d86b0d9b0536984dc62389b85bbbb Mon Sep 17 00:00:00 2001
+From: Archana-Shinde1 <archana.shinde1@ibm.com>
+Date: Mon, 7 Apr 2025 15:05:47 +0000
+Subject: [PATCH] Fix of CVE-2024-5206
+
+---
+ sklearn/feature_extraction/tests/test_text.py | 42 -------------------
+ sklearn/feature_extraction/text.py            | 36 +---------------
+ 2 files changed, 2 insertions(+), 76 deletions(-)
+
+diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py
+index fc35053b4..75d968f63 100644
+--- a/sklearn/feature_extraction/tests/test_text.py
++++ b/sklearn/feature_extraction/tests/test_text.py
+@@ -748,21 +748,11 @@ def test_feature_names():
+ @pytest.mark.parametrize("Vectorizer", (CountVectorizer, TfidfVectorizer))
+ def test_vectorizer_max_features(Vectorizer):
+     expected_vocabulary = {"burger", "beer", "salad", "pizza"}
+-    expected_stop_words = {
+-        "celeri",
+-        "tomato",
+-        "copyright",
+-        "coke",
+-        "sparkling",
+-        "water",
+-        "the",
+-    }
+ 
+     # test bounded number of extracted features
+     vectorizer = Vectorizer(max_df=0.6, max_features=4)
+     vectorizer.fit(ALL_FOOD_DOCS)
+     assert set(vectorizer.vocabulary_) == expected_vocabulary
+-    assert vectorizer.stop_words_ == expected_stop_words
+ 
+ 
+ def test_count_vectorizer_max_features():
+@@ -797,21 +787,16 @@ def test_vectorizer_max_df():
+     vect.fit(test_data)
+     assert "a" in vect.vocabulary_.keys()
+     assert len(vect.vocabulary_.keys()) == 6
+-    assert len(vect.stop_words_) == 0
+ 
+     vect.max_df = 0.5  # 0.5 * 3 documents -> max_doc_count == 1.5
+     vect.fit(test_data)
+     assert "a" not in vect.vocabulary_.keys()  # {ae} ignored
+     assert len(vect.vocabulary_.keys()) == 4  # {bcdt} remain
+-    assert "a" in vect.stop_words_
+-    assert len(vect.stop_words_) == 2
+ 
+     vect.max_df = 1
+     vect.fit(test_data)
+     assert "a" not in vect.vocabulary_.keys()  # {ae} ignored
+     assert len(vect.vocabulary_.keys()) == 4  # {bcdt} remain
+-    assert "a" in vect.stop_words_
+-    assert len(vect.stop_words_) == 2
+ 
+ 
+ def test_vectorizer_min_df():
+@@ -820,21 +805,16 @@ def test_vectorizer_min_df():
+     vect.fit(test_data)
+     assert "a" in vect.vocabulary_.keys()
+     assert len(vect.vocabulary_.keys()) == 6
+-    assert len(vect.stop_words_) == 0
+ 
+     vect.min_df = 2
+     vect.fit(test_data)
+     assert "c" not in vect.vocabulary_.keys()  # {bcdt} ignored
+     assert len(vect.vocabulary_.keys()) == 2  # {ae} remain
+-    assert "c" in vect.stop_words_
+-    assert len(vect.stop_words_) == 4
+ 
+     vect.min_df = 0.8  # 0.8 * 3 documents -> min_doc_count == 2.4
+     vect.fit(test_data)
+     assert "c" not in vect.vocabulary_.keys()  # {bcdet} ignored
+     assert len(vect.vocabulary_.keys()) == 1  # {a} remains
+-    assert "c" in vect.stop_words_
+-    assert len(vect.stop_words_) == 5
+ 
+ 
+ def test_count_binary_occurrences():
+@@ -1147,28 +1127,6 @@ def test_countvectorizer_vocab_dicts_when_pickling():
+         )
+ 
+ 
+-def test_stop_words_removal():
+-    # Ensure that deleting the stop_words_ attribute doesn't affect transform
+-
+-    fitted_vectorizers = (
+-        TfidfVectorizer().fit(JUNK_FOOD_DOCS),
+-        CountVectorizer(preprocessor=strip_tags).fit(JUNK_FOOD_DOCS),
+-        CountVectorizer(strip_accents=strip_eacute).fit(JUNK_FOOD_DOCS),
+-    )
+-
+-    for vect in fitted_vectorizers:
+-        vect_transform = vect.transform(JUNK_FOOD_DOCS).toarray()
+-
+-        vect.stop_words_ = None
+-        stop_None_transform = vect.transform(JUNK_FOOD_DOCS).toarray()
+-
+-        delattr(vect, "stop_words_")
+-        stop_del_transform = vect.transform(JUNK_FOOD_DOCS).toarray()
+-
+-        assert_array_equal(stop_None_transform, vect_transform)
+-        assert_array_equal(stop_del_transform, vect_transform)
+-
+-
+ def test_pickling_transformer():
+     X = CountVectorizer().fit_transform(JUNK_FOOD_DOCS)
+     orig = TfidfTransformer().fit(X)
+diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py
+index 4b4b4396d..fa38a1c1a 100644
+--- a/sklearn/feature_extraction/text.py
++++ b/sklearn/feature_extraction/text.py
+@@ -1075,15 +1075,6 @@ class CountVectorizer(_VectorizerMixin, BaseEstimator):
+         True if a fixed vocabulary of term to indices mapping
+         is provided by the user.
+ 
+-    stop_words_ : set
+-        Terms that were ignored because they either:
+-
+-          - occurred in too many documents (`max_df`)
+-          - occurred in too few documents (`min_df`)
+-          - were cut off by feature selection (`max_features`).
+-
+-        This is only available if no vocabulary was given.
+-
+     See Also
+     --------
+     HashingVectorizer : Convert a collection of text documents to a
+@@ -1092,12 +1083,6 @@ class CountVectorizer(_VectorizerMixin, BaseEstimator):
+     TfidfVectorizer : Convert a collection of raw documents to a matrix
+         of TF-IDF features.
+ 
+-    Notes
+-    -----
+-    The ``stop_words_`` attribute can get large and increase the model size
+-    when pickling. This attribute is provided only for introspection and can
+-    be safely removed using delattr or set to None before pickling.
+-
+     Examples
+     --------
+     >>> from sklearn.feature_extraction.text import CountVectorizer
+@@ -1236,19 +1221,17 @@ class CountVectorizer(_VectorizerMixin, BaseEstimator):
+             mask = new_mask
+ 
+         new_indices = np.cumsum(mask) - 1  # maps old indices to new
+-        removed_terms = set()
+         for term, old_index in list(vocabulary.items()):
+             if mask[old_index]:
+                 vocabulary[term] = new_indices[old_index]
+             else:
+                 del vocabulary[term]
+-                removed_terms.add(term)
+         kept_indices = np.where(mask)[0]
+         if len(kept_indices) == 0:
+             raise ValueError(
+                 "After pruning, no terms remain. Try a lower min_df or a higher max_df."
+             )
+-        return X[:, kept_indices], removed_terms
++        return X[:, kept_indices]
+ 
+     def _count_vocab(self, raw_documents, fixed_vocab):
+         """Create sparse feature matrix, and vocabulary where fixed_vocab=False"""
+@@ -1393,7 +1376,7 @@ class CountVectorizer(_VectorizerMixin, BaseEstimator):
+                 raise ValueError("max_df corresponds to < documents than min_df")
+             if max_features is not None:
+                 X = self._sort_features(X, vocabulary)
+-            X, self.stop_words_ = self._limit_features(
++            X = self._limit_features(
+                 X, vocabulary, max_doc_count, min_doc_count, max_features
+             )
+             if max_features is None:
+@@ -1920,15 +1903,6 @@ class TfidfVectorizer(CountVectorizer):
+         The inverse document frequency (IDF) vector; only defined
+         if ``use_idf`` is True.
+ 
+-    stop_words_ : set
+-        Terms that were ignored because they either:
+-
+-          - occurred in too many documents (`max_df`)
+-          - occurred in too few documents (`min_df`)
+-          - were cut off by feature selection (`max_features`).
+-
+-        This is only available if no vocabulary was given.
+-
+     See Also
+     --------
+     CountVectorizer : Transforms text into a sparse matrix of n-gram counts.
+@@ -1936,12 +1910,6 @@ class TfidfVectorizer(CountVectorizer):
+     TfidfTransformer : Performs the TF-IDF transformation from a provided
+         matrix of counts.
+ 
+-    Notes
+-    -----
+-    The ``stop_words_`` attribute can get large and increase the model size
+-    when pickling. This attribute is provided only for introspection and can
+-    be safely removed using delattr or set to None before pickling.
+-
+     Examples
+     --------
+     >>> from sklearn.feature_extraction.text import TfidfVectorizer
+-- 
+2.40.1
+
diff --git a/recipe/meta.yaml b/recipe/meta.yaml
index 854b575..fdf70a1 100644
--- a/recipe/meta.yaml
+++ b/recipe/meta.yaml
@@ -8,6 +8,8 @@ package:
 source:
   url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
   sha256: "8be549886f5eda46436b6e555b0e4873b4f10aa21c07df45c4bc1735afbccd7a"
+  patches:
+    - 0001-Fix-of-CVE-2024-5206.patch
 
 build:
   number: 2
@@ -32,7 +34,7 @@ requirements:
     - scipy 1.9.3   # [py<311]
     - scipy 1.10.0  # [py==311]
     - scipy 1.11  # [py==312]
-    - setuptools
+    - setuptools {{ setuptools }}
     - wheel
     # mkl variant pulls in intel-openmp which conflicts with llvm-openmp. i.e. force to use openblas variant of numpy, scipy, etc.
     - blas=*=openblas  # [osx and x86_64]
@@ -41,7 +43,7 @@ requirements:
     - joblib >=1.1.1
     - {{ pin_compatible('numpy') }}
     # There is some problem on osx-64 when numpy 1.25 for python 3.11 is used - 48 tests fail badly.
-    - numpy <1.25  # [osx-64 and py==311]
+#    - numpy <1.25  # [osx-64 and py==311]
     - scipy >=1.5.0
     - threadpoolctl >=2.0.0
     - llvm-openmp  # [osx]
@@ -49,17 +51,6 @@ requirements:
     # mkl variant pulls in intel-openmp which conflicts with llvm-openmp. i.e. force to use openblas variant of numpy, scipy, etc.
     - blas=*=openblas  # [osx and x86_64]
 
-# Some tests take alot of memory, and seem to cause segfaults when memory runs out
-{% set test_cpus = 1 %}
-
-{% set tests_to_skip = "_not_a_real_test" %}
-# https://github.com/scikit-learn/scikit-learn/issues/20335
-{% set tests_to_skip = tests_to_skip + " or test_loadings_converges" %}
-# Numerically unstable test numerical difference in test
-{% set tests_to_skip = tests_to_skip + " or test_mlp_regressor_dtypes_casting" %}         # [ppc64le]
-# The following test seems to be crashing CI OS.
-{% set tests_to_skip = tests_to_skip + " or test_non_negative_factorization_consistency" %}         # [osx and arm64]
-
 test:
   requires:
     - cython >=0.29.24
@@ -87,7 +78,7 @@ test:
     - set OMP_NUM_THREADS=1               # [win]
     - export OPENBLAS_NUM_THREADS=1       # [not win]
     - export OMP_NUM_THREADS=1            # [not win]
-    - pytest --timeout 300 -n {{ test_cpus }} --verbose --pyargs sklearn -k "not ({{ tests_to_skip }})"
+    - pytest --verbose --pyargs sklearn.datasets.tests
 
 about:
   home: https://scikit-learn.org/
-- 
2.40.1

